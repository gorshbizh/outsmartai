# LLM Configuration
LLM_PROVIDER=openai
LLM_API_KEY=<you_api_key>

# Server Configuration  
PORT=3000
BACKEND_PORT=5000
BACKEND_URL=http://localhost:5000
FLASK_DEBUG=False