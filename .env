# LLM Configuration
LLM_PROVIDER=openai
LLM_API_KEY=your_api_key
# Server Configuration  
PORT=3000
BACKEND_PORT=5000
BACKEND_URL=http://localhost:5000
FLASK_DEBUG=False